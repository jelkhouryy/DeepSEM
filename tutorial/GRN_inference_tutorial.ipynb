{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Beeline benchmark to benchmark the performance of DeepSEM.\n",
    "The data preparation process are shown in below.\n",
    "1. Download raw data from https://doi.org/10.5281/zenodo.3378975, which is provided by BEELINE benchmark\n",
    "2. Use the preoprocess code in https://github.com/Murali-group/Beeline/blob/master/generateExpInputs.py to generate dataset.\n",
    "\n",
    "We also provide demo data as shown in ../demo_data/GRN_inference/input "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run DeepSEM by using following command:\n",
    "for cell type specific GRN inference task: python main.py --task non_celltype_GRN --data_file demo_data/GRN_inference/input/500_STRING_hESC/data.csv --net_file demo_data/GRN_inference/input/500_STRING_hESC/label.csv --setting new --alpha 100 --beta 1 --n_epoch 90 --save_name out\n",
    "\n",
    "\n",
    "for cell type non-specific GRN inference task: python main.py --task celltype_GRN --data_file demo_data/GRN_inference/input/500_ChIP-seq_hESC/data.csv --net_file demo_data/GRN_inference/input/500_ChIP-seq_hESC/label.csv --setting new --alpha 0.1 --beta 0.01 --n_epochs 150  --save_name out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using inverse\n",
      "dir exist\n",
      "VAE_EAD(\n",
      "  (inference): InferenceNet(\n",
      "    (inference_qyx): ModuleList(\n",
      "      (0): Linear(in_features=910, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): GumbelSoftmax(\n",
      "        (logits): Linear(in_features=128, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (inference_qzyx): ModuleList(\n",
      "      (0): Linear(in_features=2, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Gaussian(\n",
      "        (mu): Linear(in_features=128, out_features=1, bias=True)\n",
      "        (var): Linear(in_features=128, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generative): GenerativeNet(\n",
      "    (y_mu): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=128, out_features=910, bias=True)\n",
      "    )\n",
      "    (y_var): Sequential(\n",
      "      (0): Linear(in_features=1, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=128, out_features=910, bias=True)\n",
      "    )\n",
      "    (generative_pxz): ModuleList(\n",
      "      (0): Linear(in_features=1, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "epoch: 1 Ep: 107 Epr: 1.0450096454324784 loss: 0.677698959906896 mse_loss: 0.6503755350907644 kl_loss: 0.02717844891594723 sparse_loss: 0.00014495258255919907\n",
      "epoch: 2 Ep: 84 Epr: 0.8203814038909176 loss: 0.669007291396459 mse_loss: 0.6413958271344503 kl_loss: 0.027450017592248816 sparse_loss: 0.0001614179454918485\n",
      "epoch: 4 Ep: 86 Epr: 0.839914294459749 loss: 0.27226613213618595 mse_loss: 0.23520035420854887 kl_loss: 0.03687634582941731 sparse_loss: 0.0001894377661907735\n",
      "epoch: 5 Ep: 91 Epr: 0.8887465208818275 loss: 0.23283623655637106 mse_loss: 0.19310533379515013 kl_loss: 0.03950792131945491 sparse_loss: 0.00022297426524649686\n",
      "epoch: 7 Ep: 94 Epr: 0.9180458567350744 loss: 0.13464363726476827 mse_loss: 0.08976656136413415 kl_loss: 0.04462981969118118 sparse_loss: 0.0002472507403581403\n",
      "epoch: 8 Ep: 99 Epr: 0.966878083157153 loss: 0.12157882563769817 mse_loss: 0.0745796908934911 kl_loss: 0.04673314575726787 sparse_loss: 0.0002659893822662222\n",
      "epoch: 10 Ep: 107 Epr: 1.0450096454324784 loss: 0.0997525950272878 mse_loss: 0.050897264232238136 kl_loss: 0.04857512563467026 sparse_loss: 0.0002802077166658516\n",
      "epoch: 11 Ep: 113 Epr: 1.1036083171389726 loss: 0.09586358008285363 mse_loss: 0.04577279184013605 kl_loss: 0.04979974667852124 sparse_loss: 0.00029104302908914786\n",
      "epoch: 13 Ep: 130 Epr: 1.2696378869740392 loss: 0.08738648084302743 mse_loss: 0.03667361568659544 kl_loss: 0.05041283338020245 sparse_loss: 0.000300032326777\n",
      "epoch: 14 Ep: 142 Epr: 1.3868352303870275 loss: 0.08579271410902341 mse_loss: 0.03429760690778494 kl_loss: 0.05118765030056238 sparse_loss: 0.00030745846743229777\n",
      "epoch: 16 Ep: 156 Epr: 1.523565464368847 loss: 0.0814340952783823 mse_loss: 0.029794211344172556 kl_loss: 0.05132595201333364 sparse_loss: 0.00031393361859954894\n",
      "epoch: 17 Ep: 172 Epr: 1.679828588919498 loss: 0.08056025517483552 mse_loss: 0.02839164777348439 kl_loss: 0.051849227864295244 sparse_loss: 0.0003193803786416538\n",
      "epoch: 19 Ep: 189 Epr: 1.8458581587545646 loss: 0.07804637029767036 mse_loss: 0.02590658205250899 kl_loss: 0.05181535721446077 sparse_loss: 0.0003244321511980767\n",
      "epoch: 20 Ep: 207 Epr: 2.021654173874047 loss: 0.0775533386816581 mse_loss: 0.024974859009186428 kl_loss: 0.052249785823126636 sparse_loss: 0.0003286953021112519\n",
      "epoch: 22 Ep: 224 Epr: 2.1876837437091137 loss: 0.07577817824979623 mse_loss: 0.023249840674300987 kl_loss: 0.05219568001727263 sparse_loss: 0.0003326586641681691\n",
      "epoch: 23 Ep: 236 Epr: 2.304881087122102 loss: 0.07541773840785027 mse_loss: 0.022595415823161602 kl_loss: 0.05248627190788587 sparse_loss: 0.0003360512273502536\n",
      "epoch: 25 Ep: 252 Epr: 2.461144211672753 loss: 0.07413752563297749 mse_loss: 0.02143942005932331 kl_loss: 0.052358930154393114 sparse_loss: 0.0003391751937063721\n",
      "epoch: 26 Ep: 263 Epr: 2.5685751098013254 loss: 0.07396178940931956 mse_loss: 0.021010451018810272 kl_loss: 0.052609194070100784 sparse_loss: 0.0003421462291347173\n",
      "epoch: 28 Ep: 280 Epr: 2.734604679636392 loss: 0.07294319818417232 mse_loss: 0.020078698949267466 kl_loss: 0.05251970545699199 sparse_loss: 0.00034479535194501903\n",
      "epoch: 29 Ep: 296 Epr: 2.8908678041870433 loss: 0.07280244616170724 mse_loss: 0.01979928572351734 kl_loss: 0.05265619481603304 sparse_loss: 0.00034696757938945666\n",
      "epoch: 31 Ep: 302 Epr: 2.949466475893537 loss: 0.07204049515227477 mse_loss: 0.01913991306597988 kl_loss: 0.05255139355237285 sparse_loss: 0.0003491909495399644\n",
      "epoch: 32 Ep: 304 Epr: 2.9689993664623686 loss: 0.07194432678321998 mse_loss: 0.018947571671257418 kl_loss: 0.05264569850017627 sparse_loss: 0.0003510569586069323\n",
      "epoch: 34 Ep: 322 Epr: 3.144795381581851 loss: 0.07138560712337494 mse_loss: 0.018471347478528816 kl_loss: 0.05256128326679269 sparse_loss: 0.00035297774835877743\n",
      "epoch: 35 Ep: 333 Epr: 3.2522262797104236 loss: 0.07118124204377334 mse_loss: 0.01820021743575732 kl_loss: 0.052626469327757754 sparse_loss: 0.00035455514686570194\n",
      "epoch: 37 Ep: 337 Epr: 3.291292060848086 loss: 0.07075013220310211 mse_loss: 0.017859695324053366 kl_loss: 0.05253427165249983 sparse_loss: 0.00035616534053891275\n",
      "epoch: 38 Ep: 348 Epr: 3.3987229589766588 loss: 0.0706795584410429 mse_loss: 0.017737889507164557 kl_loss: 0.052584194423009954 sparse_loss: 0.0003574756895735239\n",
      "epoch: 40 Ep: 357 Epr: 3.4866209665364 loss: 0.07020804844796658 mse_loss: 0.017370382323861122 kl_loss: 0.05247894829759995 sparse_loss: 0.00035871915072978783\n",
      "epoch: 41 Ep: 360 Epr: 3.515920302389647 loss: 0.07012345766027768 mse_loss: 0.017277648206800222 kl_loss: 0.05248594501366218 sparse_loss: 0.00035986450772422057\n",
      "epoch: 43 Ep: 367 Epr: 3.584285419380557 loss: 0.06978583273788293 mse_loss: 0.01706618924314777 kl_loss: 0.052358796975264944 sparse_loss: 0.0003608473731825749\n",
      "epoch: 44 Ep: 369 Epr: 3.6038183099493883 loss: 0.06962078996002674 mse_loss: 0.01695461788525184 kl_loss: 0.05230453331023455 sparse_loss: 0.0003616413353787114\n",
      "epoch: 46 Ep: 379 Epr: 3.701482762793545 loss: 0.06932227127254009 mse_loss: 0.016725744275997084 kl_loss: 0.05223381302009026 sparse_loss: 0.00036271440573424724\n",
      "epoch: 47 Ep: 383 Epr: 3.7405485439312076 loss: 0.06922971146802108 mse_loss: 0.016644475593542058 kl_loss: 0.05222179880365729 sparse_loss: 0.000363439045031555\n",
      "epoch: 49 Ep: 380 Epr: 3.7112492080779607 loss: 0.06891960340241592 mse_loss: 0.01652304649663468 kl_loss: 0.05203263539200028 sparse_loss: 0.00036392282830396044\n",
      "epoch: 50 Ep: 388 Epr: 3.789380770353286 loss: 0.06887124789257844 mse_loss: 0.016479528121029336 kl_loss: 0.0520270555280149 sparse_loss: 0.0003646631133354579\n",
      "epoch: 52 Ep: 388 Epr: 3.789380770353286 loss: 0.06862429218987624 mse_loss: 0.01634415650429825 kl_loss: 0.05191476518909136 sparse_loss: 0.00036537229364815477\n",
      "epoch: 53 Ep: 391 Epr: 3.8186801062065334 loss: 0.06856903433799744 mse_loss: 0.01636686207105716 kl_loss: 0.051836465485394 sparse_loss: 0.00036570899101207033\n",
      "epoch: 55 Ep: 398 Epr: 3.8870452231974433 loss: 0.06834673633178075 mse_loss: 0.01622100197710097 kl_loss: 0.05175924673676491 sparse_loss: 0.00036648843039680895\n",
      "epoch: 56 Ep: 402 Epr: 3.9261110043351057 loss: 0.06820288486778736 mse_loss: 0.0161568489857018 kl_loss: 0.05167912396912774 sparse_loss: 0.00036691411757298437\n",
      "epoch: 58 Ep: 402 Epr: 3.9261110043351057 loss: 0.06801687801877658 mse_loss: 0.01609577191993594 kl_loss: 0.05155381668979923 sparse_loss: 0.0003672890258409704\n",
      "epoch: 59 Ep: 401 Epr: 3.9163445590506902 loss: 0.06800109955171744 mse_loss: 0.016143083029116195 kl_loss: 0.051490199441711106 sparse_loss: 0.00036781807769633207\n",
      "epoch: 61 Ep: 405 Epr: 3.9554103401883527 loss: 0.06777664584418137 mse_loss: 0.0159903047606349 kl_loss: 0.051417873706668615 sparse_loss: 0.0003684689703125817\n",
      "epoch: 62 Ep: 407 Epr: 3.974943230757184 loss: 0.06770248462756474 mse_loss: 0.0160094634629786 kl_loss: 0.051324278116226196 sparse_loss: 0.0003687443580323209\n",
      "epoch: 64 Ep: 409 Epr: 3.9944761213260156 loss: 0.06746573746204376 mse_loss: 0.015877908173327644 kl_loss: 0.051218713633716106 sparse_loss: 0.00036911731634366635\n",
      "epoch: 65 Ep: 415 Epr: 4.0530747930325095 loss: 0.06736909411847591 mse_loss: 0.015886903662855428 kl_loss: 0.05111292159805695 sparse_loss: 0.0003692692819943962\n",
      "epoch: 67 Ep: 416 Epr: 4.062841238316925 loss: 0.06731414546569188 mse_loss: 0.015880822281663615 kl_loss: 0.051063243144502245 sparse_loss: 0.0003700808423066822\n",
      "epoch: 68 Ep: 419 Epr: 4.092140574170172 loss: 0.06718349518875281 mse_loss: 0.015892207932968933 kl_loss: 0.0509212634836634 sparse_loss: 0.0003700257996873309\n",
      "epoch: 70 Ep: 423 Epr: 4.131206355307835 loss: 0.06707024201750755 mse_loss: 0.01582550668778519 kl_loss: 0.05087374725068609 sparse_loss: 0.00037098974280525\n",
      "epoch: 71 Ep: 426 Epr: 4.160505691161083 loss: 0.06693539395928383 mse_loss: 0.015784409052381914 kl_loss: 0.05077980412170291 sparse_loss: 0.0003711819614788207\n",
      "epoch: 73 Ep: 421 Epr: 4.111673464739003 loss: 0.06674872525036335 mse_loss: 0.015665761350343626 kl_loss: 0.05071123084053397 sparse_loss: 0.0003717346941508974\n",
      "epoch: 74 Ep: 421 Epr: 4.111673464739003 loss: 0.06668348424136639 mse_loss: 0.015708806614081066 kl_loss: 0.050602668430656195 sparse_loss: 0.00037201066394724575\n",
      "epoch: 76 Ep: 419 Epr: 4.092140574170172 loss: 0.06662219204008579 mse_loss: 0.015722828761984903 kl_loss: 0.050526731026669346 sparse_loss: 0.000372632244155587\n",
      "epoch: 77 Ep: 429 Epr: 4.189805027014329 loss: 0.0665204580873251 mse_loss: 0.015640549439315993 kl_loss: 0.050506578758358955 sparse_loss: 0.00037333039169122156\n",
      "epoch: 79 Ep: 433 Epr: 4.228870808151992 loss: 0.06639822199940681 mse_loss: 0.015628289120892685 kl_loss: 0.05039612234880527 sparse_loss: 0.0003738106194456729\n",
      "epoch: 80 Ep: 430 Epr: 4.199571472298745 loss: 0.06628784040609996 mse_loss: 0.015602883649989963 kl_loss: 0.050310757321616016 sparse_loss: 0.0003741991361797166\n",
      "epoch: 82 Ep: 438 Epr: 4.2777030345740705 loss: 0.06628088032205899 mse_loss: 0.015623407516007623 kl_loss: 0.050282476004213095 sparse_loss: 0.00037499659083550796\n",
      "epoch: 83 Ep: 436 Epr: 4.2581701440052395 loss: 0.06619775171081226 mse_loss: 0.015565827954560518 kl_loss: 0.05025595333427191 sparse_loss: 0.00037597044138237834\n",
      "epoch: 85 Ep: 437 Epr: 4.267936589289655 loss: 0.06607874979575475 mse_loss: 0.01553189211214582 kl_loss: 0.05017042843004068 sparse_loss: 0.0003764306117470066\n",
      "epoch: 86 Ep: 442 Epr: 4.316768815711733 loss: 0.06594971319039662 mse_loss: 0.015489285423730811 kl_loss: 0.05008347751572728 sparse_loss: 0.00037695241674858454\n",
      "epoch: 88 Ep: 445 Epr: 4.34606815156498 loss: 0.06592874974012375 mse_loss: 0.015569541836157441 kl_loss: 0.049981893661121525 sparse_loss: 0.0003773154506537442\n",
      "epoch: 89 Ep: 442 Epr: 4.316768815711733 loss: 0.06587117289503415 mse_loss: 0.015477484635387858 kl_loss: 0.05001501770069202 sparse_loss: 0.00037867073600258056\n",
      "epoch: 91 Ep: 439 Epr: 4.287469479858486 loss: 0.06571690117319424 mse_loss: 0.015439303359016776 kl_loss: 0.049898526165634394 sparse_loss: 0.0003790728442254476\n",
      "epoch: 92 Ep: 437 Epr: 4.267936589289655 loss: 0.06571878492832184 mse_loss: 0.015466179233044386 kl_loss: 0.049872661319871746 sparse_loss: 0.00037994319427525625\n",
      "epoch: 94 Ep: 440 Epr: 4.2972359251429015 loss: 0.06568331085145473 mse_loss: 0.015494469398011764 kl_loss: 0.049808194395154715 sparse_loss: 0.0003806471868301742\n",
      "epoch: 95 Ep: 441 Epr: 4.307002370427318 loss: 0.06564148825903733 mse_loss: 0.015461905704190334 kl_loss: 0.0497978792215387 sparse_loss: 0.0003817030737991445\n",
      "epoch: 97 Ep: 444 Epr: 4.336301706280564 loss: 0.06555541791021824 mse_loss: 0.015434543912609419 kl_loss: 0.0497385550600787 sparse_loss: 0.0003823205503673914\n",
      "epoch: 98 Ep: 438 Epr: 4.2777030345740705 loss: 0.06553660954038303 mse_loss: 0.015402260158831874 kl_loss: 0.04975081297258536 sparse_loss: 0.00038353613490471616\n",
      "epoch: 100 Ep: 440 Epr: 4.2972359251429015 loss: 0.06534199540813763 mse_loss: 0.01536404232804974 kl_loss: 0.049594103203465544 sparse_loss: 0.00038385172956623137\n",
      "epoch: 101 Ep: 438 Epr: 4.2777030345740705 loss: 0.0653172992169857 mse_loss: 0.015355142842357358 kl_loss: 0.04957748778785268 sparse_loss: 0.0003846700055873953\n",
      "epoch: 103 Ep: 435 Epr: 4.248403698720823 loss: 0.06528178912897904 mse_loss: 0.015314698141689101 kl_loss: 0.049581210128962994 sparse_loss: 0.0003858801137539558\n",
      "epoch: 104 Ep: 427 Epr: 4.170272136445498 loss: 0.06524692972501119 mse_loss: 0.015319337214653691 kl_loss: 0.049540646839886904 sparse_loss: 0.0003869459445316655\n",
      "epoch: 106 Ep: 425 Epr: 4.150739245876666 loss: 0.06519389587144057 mse_loss: 0.015325885266065598 kl_loss: 0.049480415104577936 sparse_loss: 0.00038759658006407943\n",
      "epoch: 107 Ep: 424 Epr: 4.140972800592251 loss: 0.06519123166799545 mse_loss: 0.015315300086513162 kl_loss: 0.04948711379741629 sparse_loss: 0.0003888191713485867\n",
      "epoch: 109 Ep: 432 Epr: 4.219104362867577 loss: 0.06511623101929824 mse_loss: 0.01533644056568543 kl_loss: 0.049390447636445366 sparse_loss: 0.0003893435520391601\n",
      "epoch: 110 Ep: 424 Epr: 4.140972800592251 loss: 0.06511616023878257 mse_loss: 0.015328541863709688 kl_loss: 0.04939713841304183 sparse_loss: 0.00039048114316149923\n",
      "epoch: 112 Ep: 423 Epr: 4.131206355307835 loss: 0.06499637259791295 mse_loss: 0.01523349597118795 kl_loss: 0.049371365923434496 sparse_loss: 0.00039151100160476443\n",
      "epoch: 113 Ep: 421 Epr: 4.111673464739003 loss: 0.06501240221162637 mse_loss: 0.015284628762553135 kl_loss: 0.049335514195263386 sparse_loss: 0.00039225956667602685\n",
      "epoch: 115 Ep: 432 Epr: 4.219104362867577 loss: 0.06496076720456283 mse_loss: 0.015283514202261964 kl_loss: 0.04928399948403239 sparse_loss: 0.00039325395482592285\n",
      "epoch: 116 Ep: 426 Epr: 4.160505691161083 loss: 0.06494700132558744 mse_loss: 0.015294587472453713 kl_loss: 0.049258341236660876 sparse_loss: 0.00039407402073265985\n",
      "epoch: 118 Ep: 421 Epr: 4.111673464739003 loss: 0.0649067930256327 mse_loss: 0.015253719330454866 kl_loss: 0.04925789777189493 sparse_loss: 0.00039517742455548915\n",
      "epoch: 119 Ep: 426 Epr: 4.160505691161083 loss: 0.06481988914310932 mse_loss: 0.015205172200997671 kl_loss: 0.04921867434556285 sparse_loss: 0.00039604529592907056\n"
     ]
    }
   ],
   "source": [
    "#! python main.py --task non_celltype_GRN --data_file demo_data/GRN_inference/input/500_STRING_hESC/data.csv --net_file demo_data/GRN_inference/input/500_STRING_hESC/label.csv --setting new --alpha 100 --beta 1 --n_epoch 90 --save_name out\n",
    "!python ../main.py --task celltype_GRN --data_file ../demo_data/GRN_inference/input/500_STRING_hESC/data.csv \\\n",
    "    --net_file ../demo_data/GRN_inference/input/500_STRING_hESC/label.csv --setting new \\\n",
    "    --alpha 0.1 --beta 0.01 --n_epochs 120  --save_name out/500_STRING_hESC/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate EPR values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.160505691161083"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "output = pd.read_csv('out/500_STRING_hESC/GRN_inference_result.tsv',sep='\\t')\n",
    "output['EdgeWeight'] = abs(output['EdgeWeight'])\n",
    "output = output.sort_values('EdgeWeight',ascending=False)\n",
    "label = pd.read_csv('../demo_data/GRN_inference/input/500_STRING_hESC/label.csv')\n",
    "TFs = set(label['Gene1'])\n",
    "Genes = set(label['Gene1'])| set(label['Gene2'])\n",
    "output = output[output['TF'].apply(lambda x: x in TFs)]\n",
    "output = output[output['Target'].apply(lambda x: x in Genes)]\n",
    "label_set = set(label['Gene1']+'|'+label['Gene2'])\n",
    "output = output.iloc[:len(label_set)]\n",
    "len(set(output['TF']+'|'+output['Target']) & label_set) / (len(label_set)**2/(len(TFs)*len(Genes)-len(TFs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate AUPR ratio values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC =  0.03559167427935618\n",
      "1.482618555704137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "preds,labels,randoms = [] ,[],[]\n",
    "res_d = {}\n",
    "l = []\n",
    "p= []\n",
    "for item in (output.to_dict('records')):\n",
    "        res_d[item['TF'] + '|' + item['Target']] = item['EdgeWeight']\n",
    "for item in (set(label['Gene1'])):\n",
    "        for item2 in  set(label['Gene1'])| set(label['Gene2']):\n",
    "            if item+ '|' + item2 in label_set:\n",
    "                l.append(1)\n",
    "            else:\n",
    "                l.append(0)\n",
    "            if item + '|' + item2 in res_d:\n",
    "                p.append(res_d[item + '|' + item2])\n",
    "            else:\n",
    "                p.append(-1)\n",
    "                \n",
    "print(\"AUPRC = \", average_precision_score(l,p))\n",
    "print(average_precision_score(l,p)/np.mean(l))\n",
    "precision, recall, thresholds = precision_recall_curve(l, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'precision')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble DeepSEM result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv does not exist: '../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17913/2596218852.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EdgeWeight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EdgeWeight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepsem/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepsem/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepsem/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepsem/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepsem/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv does not exist: '../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv'"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in range(10):\n",
    "    res.append(pd.read_csv('../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv',sep='\\t'))\n",
    "res = pd.concat(res)\n",
    "res['EdgeWeight'] = abs(res['EdgeWeight'])\n",
    "res.groupby(['Gene1','Gene2']).mean()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2738dfb9bd63bdcf641cb5b69246b4d1b6f8afb0544341910e01f4e96fcddd2e"
  },
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
