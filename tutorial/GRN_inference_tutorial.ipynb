{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Beeline benchmark to benchmark the performance of DeepSEM.\n",
    "The data preparation process are shown in below.\n",
    "1. Download raw data from https://doi.org/10.5281/zenodo.3378975, which is provided by BEELINE benchmark\n",
    "2. Use the preoprocess code in https://github.com/Murali-group/Beeline/blob/master/generateExpInputs.py to generate dataset.\n",
    "\n",
    "We also provide demo data as shown in ../demo_data/GRN_inference/input "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run DeepSEM by using following command:\n",
    "for cell type specific GRN inference task: python main.py --task non_celltype_GRN --data_file demo_data/GRN_inference/input/500_STRING_hESC/data.csv --net_file demo_data/GRN_inference/input/500_STRING_hESC/label.csv --setting new --alpha 100 --beta 1 --n_epoch 90 --save_name out\n",
    "\n",
    "\n",
    "for cell type non-specific GRN inference task: python main.py --task celltype_GRN --data_file demo_data/GRN_inference/input/500_ChIP-seq_hESC/data.csv --net_file demo_data/GRN_inference/input/500_ChIP-seq_hESC/label.csv --setting new --alpha 0.1 --beta 0.01 --n_epochs 150  --save_name out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using inverse constraint\n",
      "dir exist\n",
      "epoch: 1 Ep: 657 Epr: 0.8854646273145838 loss: 0.40524541834990185 mse_loss: 0.37126381198565167 kl_loss: 0.03383117301079134 sparse_loss: 0.0001504377899739969\n",
      "epoch: 2 Ep: 644 Epr: 0.8679440182505205 loss: 0.382014736533165 mse_loss: 0.34716524680455524 kl_loss: 0.03467311446244518 sparse_loss: 0.00017638627953904992\n",
      "epoch: 4 Ep: 641 Epr: 0.8639008007741982 loss: 0.1962630165119966 mse_loss: 0.15378108620643616 kl_loss: 0.0422802638883392 sparse_loss: 0.00020166086081493026\n",
      "epoch: 5 Ep: 631 Epr: 0.8504234091864572 loss: 0.17212274049719176 mse_loss: 0.12743392090002695 kl_loss: 0.044462022526810564 sparse_loss: 0.00022679195535602048\n",
      "epoch: 7 Ep: 635 Epr: 0.8558143658215536 loss: 0.12627760569254556 mse_loss: 0.07845771685242653 kl_loss: 0.04757408440733949 sparse_loss: 0.0002458036372748514\n",
      "epoch: 8 Ep: 638 Epr: 0.8598575832978759 loss: 0.11811616457998753 mse_loss: 0.06872863943378131 kl_loss: 0.049126722694685064 sparse_loss: 0.0002608045955033352\n",
      "epoch: 10 Ep: 631 Epr: 0.8504234091864572 loss: 0.10206477157771587 mse_loss: 0.051773366828759514 kl_loss: 0.05001859754944841 sparse_loss: 0.00027280981885269284\n",
      "epoch: 11 Ep: 641 Epr: 0.8639008007741982 loss: 0.09893366321921349 mse_loss: 0.04756038822233677 kl_loss: 0.051090502024938665 sparse_loss: 0.0002827753463255552\n",
      "epoch: 13 Ep: 647 Epr: 0.8719872357268428 loss: 0.09135016612708569 mse_loss: 0.03986523828158776 kl_loss: 0.05119384825229645 sparse_loss: 0.00029108196516366053\n",
      "epoch: 14 Ep: 665 Epr: 0.8962465405847766 loss: 0.08961037173867226 mse_loss: 0.03745704175283512 kl_loss: 0.05185510373363892 sparse_loss: 0.00029822689733312774\n",
      "epoch: 16 Ep: 677 Epr: 0.9124194104900658 loss: 0.08523102725545566 mse_loss: 0.033193422170976795 kl_loss: 0.05173293004433314 sparse_loss: 0.00030467723020895693\n",
      "epoch: 17 Ep: 696 Epr: 0.9380264545067737 loss: 0.08431957600017388 mse_loss: 0.031768163510908685 kl_loss: 0.05224106181412935 sparse_loss: 0.00031035152642289177\n",
      "epoch: 19 Ep: 699 Epr: 0.942069671983096 loss: 0.08140482505162557 mse_loss: 0.029013576296468575 kl_loss: 0.05207576944182316 sparse_loss: 0.00031548061573024216\n",
      "epoch: 20 Ep: 716 Epr: 0.9649812376822556 loss: 0.08077449103196462 mse_loss: 0.0279993227062126 kl_loss: 0.05245509867866834 sparse_loss: 0.00032006963980772224\n",
      "epoch: 22 Ep: 732 Epr: 0.9865450642226413 loss: 0.0787690660605828 mse_loss: 0.026209797710180283 kl_loss: 0.05223502917215228 sparse_loss: 0.0003242407159026091\n",
      "epoch: 23 Ep: 735 Epr: 0.9905882816989636 loss: 0.07855952717363834 mse_loss: 0.02566777712975939 kl_loss: 0.052563574785987534 sparse_loss: 0.0003281771738935883\n",
      "epoch: 25 Ep: 739 Epr: 0.99597923833406 loss: 0.07684475928544998 mse_loss: 0.024173011382420857 kl_loss: 0.05233995274951061 sparse_loss: 0.00033179655292769894\n",
      "epoch: 26 Ep: 748 Epr: 1.008108890763027 loss: 0.07661840133368969 mse_loss: 0.02365316233287255 kl_loss: 0.052630120888352394 sparse_loss: 0.0003351182846624094\n",
      "epoch: 28 Ep: 758 Epr: 1.021586282350768 loss: 0.07543629904588063 mse_loss: 0.02263601791734497 kl_loss: 0.05246207024902105 sparse_loss: 0.00033821038232417777\n",
      "epoch: 29 Ep: 759 Epr: 1.022934021509542 loss: 0.0751761645078659 mse_loss: 0.022234715676556032 kl_loss: 0.05260058647642533 sparse_loss: 0.0003408630606524336\n",
      "epoch: 31 Ep: 762 Epr: 1.0269772389858642 loss: 0.07432388886809349 mse_loss: 0.021499645430594683 kl_loss: 0.05248068536942204 sparse_loss: 0.00034355928558701027\n",
      "epoch: 32 Ep: 763 Epr: 1.0283249781446384 loss: 0.07407135640581448 mse_loss: 0.02117019162202875 kl_loss: 0.05255529765660564 sparse_loss: 0.00034586676095689956\n",
      "epoch: 34 Ep: 764 Epr: 1.0296727173034126 loss: 0.07344160601496696 mse_loss: 0.020647351164370775 kl_loss: 0.052446058175216116 sparse_loss: 0.0003481966705294326\n",
      "epoch: 35 Ep: 759 Epr: 1.022934021509542 loss: 0.07330276072025299 mse_loss: 0.020395987201482058 kl_loss: 0.05255667446181178 sparse_loss: 0.00035010096568536636\n",
      "epoch: 37 Ep: 755 Epr: 1.0175430648744457 loss: 0.07257782109081745 mse_loss: 0.019806457683444023 kl_loss: 0.05241925114144882 sparse_loss: 0.00035211180268864456\n",
      "epoch: 38 Ep: 751 Epr: 1.0121521082393492 loss: 0.07246412585179011 mse_loss: 0.019648555510987837 kl_loss: 0.05246189314251145 sparse_loss: 0.0003536802008360003\n",
      "epoch: 40 Ep: 747 Epr: 1.0067611516042527 loss: 0.07200850918889046 mse_loss: 0.019331757677718997 kl_loss: 0.052321517219146095 sparse_loss: 0.0003552371563273482\n",
      "epoch: 41 Ep: 741 Epr: 0.9986747166516082 loss: 0.07186991100509961 mse_loss: 0.019127358682453632 kl_loss: 0.05238565569743514 sparse_loss: 0.0003568974619459671\n",
      "epoch: 43 Ep: 737 Epr: 0.9932837600165118 loss: 0.07146584677199523 mse_loss: 0.018860037438571453 kl_loss: 0.05224768895034989 sparse_loss: 0.00035812208564796794\n",
      "epoch: 44 Ep: 724 Epr: 0.9757631509524485 loss: 0.07132832643886407 mse_loss: 0.018705366024126608 kl_loss: 0.052263484025994934 sparse_loss: 0.0003594778827391565\n",
      "epoch: 46 Ep: 719 Epr: 0.9690244551585779 loss: 0.07090604988237222 mse_loss: 0.01842787101243933 kl_loss: 0.052117666229605675 sparse_loss: 0.00036051334366978455\n",
      "epoch: 47 Ep: 720 Epr: 0.9703721943173521 loss: 0.07077957255144914 mse_loss: 0.018289152377595503 kl_loss: 0.05212889161581794 sparse_loss: 0.00036153033094403025\n",
      "epoch: 49 Ep: 713 Epr: 0.9609380202059334 loss: 0.0705863640954097 mse_loss: 0.018246218096464872 kl_loss: 0.051977625116705894 sparse_loss: 0.00036252026378254715\n",
      "epoch: 50 Ep: 708 Epr: 0.9541993244120629 loss: 0.07040742350121339 mse_loss: 0.01809131974975268 kl_loss: 0.05195285985246301 sparse_loss: 0.0003632445756617623\n",
      "epoch: 52 Ep: 699 Epr: 0.942069671983096 loss: 0.0700923502445221 mse_loss: 0.017921990637357037 kl_loss: 0.05180635380869111 sparse_loss: 0.00036400740888590616\n",
      "epoch: 53 Ep: 689 Epr: 0.928592280395355 loss: 0.07004358557363351 mse_loss: 0.01786718851265808 kl_loss: 0.0518112787976861 sparse_loss: 0.00036511963602000225\n",
      "epoch: 55 Ep: 685 Epr: 0.9232013237602585 loss: 0.0697134155780077 mse_loss: 0.017705546071132023 kl_loss: 0.051642417131612696 sparse_loss: 0.00036545173982934404\n",
      "epoch: 56 Ep: 678 Epr: 0.9137671496488399 loss: 0.06964928346375625 mse_loss: 0.01770549298574527 kl_loss: 0.05157767981290817 sparse_loss: 0.0003661121760766643\n",
      "epoch: 58 Ep: 675 Epr: 0.9097239321725176 loss: 0.0694134421646595 mse_loss: 0.017578834512581427 kl_loss: 0.05146790544191996 sparse_loss: 0.0003667031536072803\n",
      "epoch: 59 Ep: 672 Epr: 0.9056807146961953 loss: 0.06930927187204361 mse_loss: 0.01755629254815479 kl_loss: 0.05138567912702759 sparse_loss: 0.0003673020692076534\n",
      "epoch: 61 Ep: 667 Epr: 0.8989420189023248 loss: 0.06908638837436835 mse_loss: 0.01739535480737686 kl_loss: 0.05132292707761129 sparse_loss: 0.00036810600431635976\n",
      "epoch: 62 Ep: 661 Epr: 0.8908555839496802 loss: 0.06902843589584033 mse_loss: 0.017432670729855698 kl_loss: 0.051227255103488765 sparse_loss: 0.0003685105693875812\n",
      "epoch: 64 Ep: 662 Epr: 0.8922033231084543 loss: 0.06882660773893197 mse_loss: 0.01733249829461177 kl_loss: 0.051124963288505874 sparse_loss: 0.00036914653416412574\n",
      "epoch: 65 Ep: 665 Epr: 0.8962465405847766 loss: 0.06870656398435433 mse_loss: 0.01730187563225627 kl_loss: 0.05103509904195865 sparse_loss: 0.0003695909739083921\n",
      "epoch: 67 Ep: 664 Epr: 0.8948988014260025 loss: 0.06854103070994218 mse_loss: 0.017181144872059424 kl_loss: 0.050989556747178234 sparse_loss: 0.0003703300268777336\n",
      "epoch: 68 Ep: 659 Epr: 0.888160105632132 loss: 0.06843644566833973 mse_loss: 0.017193301968897384 kl_loss: 0.050872584184010826 sparse_loss: 0.0003705591492083234\n",
      "epoch: 70 Ep: 663 Epr: 0.8935510622672284 loss: 0.06831044952074687 mse_loss: 0.017134264499569934 kl_loss: 0.0508051075351735 sparse_loss: 0.000371077881330469\n",
      "epoch: 71 Ep: 666 Epr: 0.8975942797435507 loss: 0.06829125558336575 mse_loss: 0.01720627141185105 kl_loss: 0.05071335704997182 sparse_loss: 0.00037162722340629745\n",
      "epoch: 73 Ep: 671 Epr: 0.9043329755374212 loss: 0.0681082271039486 mse_loss: 0.017106974497437477 kl_loss: 0.0506290205133458 sparse_loss: 0.0003722313873974296\n",
      "epoch: 74 Ep: 662 Epr: 0.8922033231084543 loss: 0.06798572403689225 mse_loss: 0.01705118043658634 kl_loss: 0.05056167673319578 sparse_loss: 0.00037286722848269466\n",
      "epoch: 76 Ep: 668 Epr: 0.9002897580610989 loss: 0.06787346365551154 mse_loss: 0.01701608789153397 kl_loss: 0.05048401188105345 sparse_loss: 0.0003733636694960296\n",
      "epoch: 77 Ep: 670 Epr: 0.902985236378647 loss: 0.0678251360853513 mse_loss: 0.017016383353620768 kl_loss: 0.05043452372774482 sparse_loss: 0.00037422940173807245\n",
      "epoch: 79 Ep: 668 Epr: 0.9002897580610989 loss: 0.06766229184965293 mse_loss: 0.016938580976178248 kl_loss: 0.05034903297200799 sparse_loss: 0.0003746792644960806\n",
      "epoch: 80 Ep: 668 Epr: 0.9002897580610989 loss: 0.06759601769347985 mse_loss: 0.01695817072565357 kl_loss: 0.050262459398557745 sparse_loss: 0.00037538898808027926\n",
      "epoch: 82 Ep: 672 Epr: 0.9056807146961953 loss: 0.06747173269589742 mse_loss: 0.016883240003759663 kl_loss: 0.05021255991111199 sparse_loss: 0.00037593367354323465\n",
      "epoch: 83 Ep: 675 Epr: 0.9097239321725176 loss: 0.06744311191141605 mse_loss: 0.016877579657981794 kl_loss: 0.0501886789376537 sparse_loss: 0.0003768539463635534\n",
      "epoch: 85 Ep: 678 Epr: 0.9137671496488399 loss: 0.0673712578912576 mse_loss: 0.016887757383907836 kl_loss: 0.05010602064430714 sparse_loss: 0.0003774812212213874\n",
      "epoch: 86 Ep: 675 Epr: 0.9097239321725176 loss: 0.06726082290212314 mse_loss: 0.016838787045950692 kl_loss: 0.05004407186061144 sparse_loss: 0.00037796644513340044\n",
      "epoch: 88 Ep: 680 Epr: 0.9164626279663881 loss: 0.06710312701761723 mse_loss: 0.016758988611400127 kl_loss: 0.049965392953405775 sparse_loss: 0.0003787475919428592\n",
      "epoch: 89 Ep: 682 Epr: 0.9191581062839362 loss: 0.06716334633529186 mse_loss: 0.016883350753535826 kl_loss: 0.049900598203142486 sparse_loss: 0.0003793988871620968\n",
      "epoch: 91 Ep: 681 Epr: 0.9178103671251622 loss: 0.0670181264479955 mse_loss: 0.016768686939030886 kl_loss: 0.04986909528573354 sparse_loss: 0.00038034399040043354\n",
      "epoch: 92 Ep: 685 Epr: 0.9232013237602585 loss: 0.06694682687520981 mse_loss: 0.016749804684271414 kl_loss: 0.04981594936301311 sparse_loss: 0.0003810726169225139\n",
      "epoch: 94 Ep: 691 Epr: 0.9312877587129031 loss: 0.0669226956864198 mse_loss: 0.01677166554145515 kl_loss: 0.049769063790639244 sparse_loss: 0.0003819686535280198\n",
      "epoch: 95 Ep: 691 Epr: 0.9312877587129031 loss: 0.06684851770599683 mse_loss: 0.016749226410562795 kl_loss: 0.04971670111020406 sparse_loss: 0.00038259149732766673\n",
      "epoch: 97 Ep: 695 Epr: 0.9366787153479996 loss: 0.06676302229364713 mse_loss: 0.016687051625922322 kl_loss: 0.049692284781485796 sparse_loss: 0.0003836873729596846\n",
      "epoch: 98 Ep: 697 Epr: 0.9393741936655478 loss: 0.06668682458500068 mse_loss: 0.016699367978920538 kl_loss: 0.049603371104846396 sparse_loss: 0.00038408574619097635\n",
      "epoch: 100 Ep: 700 Epr: 0.94341741114187 loss: 0.06664222540954749 mse_loss: 0.01669308457834025 kl_loss: 0.049563928352048 sparse_loss: 0.0003852148777999294\n",
      "epoch: 101 Ep: 706 Epr: 0.9515038460945147 loss: 0.06663955748081207 mse_loss: 0.016670268417025607 kl_loss: 0.04958265429983536 sparse_loss: 0.00038663495070068166\n",
      "epoch: 103 Ep: 708 Epr: 0.9541993244120629 loss: 0.06651809687415759 mse_loss: 0.01662293402478099 kl_loss: 0.049508205614984035 sparse_loss: 0.0003869583524647169\n",
      "epoch: 104 Ep: 711 Epr: 0.9582425418883852 loss: 0.06648901663720608 mse_loss: 0.016638953781997163 kl_loss: 0.049462276666114725 sparse_loss: 0.00038778626670440036\n",
      "epoch: 106 Ep: 709 Epr: 0.955547063570837 loss: 0.06641402592261632 mse_loss: 0.01660965965129435 kl_loss: 0.04941561600814263 sparse_loss: 0.0003887518638900171\n",
      "epoch: 107 Ep: 709 Epr: 0.955547063570837 loss: 0.06639624014496803 mse_loss: 0.016624117580552895 kl_loss: 0.0493825802889963 sparse_loss: 0.0003895447395431499\n",
      "epoch: 109 Ep: 713 Epr: 0.9609380202059334 loss: 0.06633737683296204 mse_loss: 0.016586115428556997 kl_loss: 0.049360585709412895 sparse_loss: 0.00039067683974280953\n",
      "epoch: 110 Ep: 718 Epr: 0.9676767159998039 loss: 0.06632812010745208 mse_loss: 0.01658874408652385 kl_loss: 0.04934785577158133 sparse_loss: 0.00039152083384882036\n",
      "epoch: 112 Ep: 723 Epr: 0.9744154117936744 loss: 0.06628173527618249 mse_loss: 0.016612732084468007 kl_loss: 0.04927677226563295 sparse_loss: 0.00039223078298770514\n",
      "epoch: 113 Ep: 727 Epr: 0.9798063684287708 loss: 0.06616891982654731 mse_loss: 0.016532230967034895 kl_loss: 0.04924357154717048 sparse_loss: 0.0003931172177544795\n",
      "epoch: 115 Ep: 727 Epr: 0.9798063684287708 loss: 0.06618997020026048 mse_loss: 0.01658323275235792 kl_loss: 0.049212730334450804 sparse_loss: 0.0003940090658337188\n",
      "epoch: 116 Ep: 729 Epr: 0.982501846746319 loss: 0.06612190480033557 mse_loss: 0.01651702495291829 kl_loss: 0.049209793408711754 sparse_loss: 0.0003950866812374443\n",
      "epoch: 118 Ep: 728 Epr: 0.9811541075875448 loss: 0.06617425537357728 mse_loss: 0.01655312239502867 kl_loss: 0.0492249452508986 sparse_loss: 0.00039618846979768324\n",
      "epoch: 119 Ep: 737 Epr: 0.9932837600165118 loss: 0.06604137582083543 mse_loss: 0.016525204371040065 kl_loss: 0.049119677394628525 sparse_loss: 0.0003964929298187296\n",
      "epoch: 121 Ep: 743 Epr: 1.0013701949691565 loss: 0.06598924069354932 mse_loss: 0.01648815340983371 kl_loss: 0.049103650730103254 sparse_loss: 0.00039743770806429285\n",
      "epoch: 122 Ep: 747 Epr: 1.0067611516042527 loss: 0.06597159740825494 mse_loss: 0.01650412256519 kl_loss: 0.0490691838786006 sparse_loss: 0.0003982924560356575\n",
      "epoch: 124 Ep: 749 Epr: 1.009456629921801 loss: 0.06589411261181037 mse_loss: 0.016428024508059025 kl_loss: 0.04906672270347675 sparse_loss: 0.0003993656403811959\n",
      "epoch: 125 Ep: 752 Epr: 1.0134998473981234 loss: 0.065994743257761 mse_loss: 0.01654577674344182 kl_loss: 0.049048738864560924 sparse_loss: 0.0004002269609676053\n",
      "epoch: 127 Ep: 753 Epr: 1.0148475865568973 loss: 0.0658745967472593 mse_loss: 0.016445559449493885 kl_loss: 0.04902815151338776 sparse_loss: 0.0004008863543276675\n",
      "epoch: 128 Ep: 755 Epr: 1.0175430648744457 loss: 0.0658544022589922 mse_loss: 0.01645752143425246 kl_loss: 0.04899525844181577 sparse_loss: 0.00040162303776014596\n",
      "epoch: 130 Ep: 762 Epr: 1.0269772389858642 loss: 0.06592124390105407 mse_loss: 0.016523139628892142 kl_loss: 0.04899542545899749 sparse_loss: 0.00040267908237486455\n",
      "epoch: 131 Ep: 768 Epr: 1.0350636739385088 loss: 0.06583544177313645 mse_loss: 0.01650638001350065 kl_loss: 0.048925740799556174 sparse_loss: 0.0004033210546670792\n",
      "epoch: 133 Ep: 773 Epr: 1.0418023697323795 loss: 0.06581209786236286 mse_loss: 0.016419258744766314 kl_loss: 0.04898813894639412 sparse_loss: 0.00040470081148669124\n",
      "epoch: 134 Ep: 773 Epr: 1.0418023697323795 loss: 0.0657677873969078 mse_loss: 0.01644110477839907 kl_loss: 0.048921472703417145 sparse_loss: 0.0004052098859877636\n",
      "epoch: 136 Ep: 769 Epr: 1.036411413097283 loss: 0.06572579933951299 mse_loss: 0.01640638189079861 kl_loss: 0.048913468761990465 sparse_loss: 0.0004059490650737037\n",
      "epoch: 137 Ep: 775 Epr: 1.0444978480499276 loss: 0.06574769504368305 mse_loss: 0.016474783265342314 kl_loss: 0.04886630938077966 sparse_loss: 0.0004066026958753355\n",
      "epoch: 139 Ep: 775 Epr: 1.0444978480499276 loss: 0.06576121846834819 mse_loss: 0.016485781176015735 kl_loss: 0.04886783643936118 sparse_loss: 0.00040760069775084656\n",
      "epoch: 140 Ep: 778 Epr: 1.04854106552625 loss: 0.06566814395288627 mse_loss: 0.016401043549800914 kl_loss: 0.04885859306280812 sparse_loss: 0.0004085066757397726\n",
      "epoch: 142 Ep: 781 Epr: 1.0525842830025722 loss: 0.06566612422466278 mse_loss: 0.016397734483083088 kl_loss: 0.04885923070833087 sparse_loss: 0.0004091604763137487\n",
      "epoch: 143 Ep: 782 Epr: 1.0539320221613464 loss: 0.06559968429307143 mse_loss: 0.01638215105049312 kl_loss: 0.04880769193793336 sparse_loss: 0.00040984283744667965\n",
      "epoch: 145 Ep: 783 Epr: 1.0552797613201204 loss: 0.06563013854126136 mse_loss: 0.016423492304359872 kl_loss: 0.04879601222152511 sparse_loss: 0.0004106362005889726\n",
      "epoch: 146 Ep: 783 Epr: 1.0552797613201204 loss: 0.06562206832071145 mse_loss: 0.0164198506778727 kl_loss: 0.04879083080838124 sparse_loss: 0.00041138701150581863\n",
      "epoch: 148 Ep: 783 Epr: 1.0552797613201204 loss: 0.06557699975868066 mse_loss: 0.016403523506596684 kl_loss: 0.04876147831479708 sparse_loss: 0.0004119987982752112\n",
      "epoch: 149 Ep: 787 Epr: 1.0606707179552168 loss: 0.06557751509050529 mse_loss: 0.01639427097203831 kl_loss: 0.048770196891079344 sparse_loss: 0.00041304782644147053\n"
     ]
    }
   ],
   "source": [
    "#! python ../main.py --task non_celltype_GRN --data_file ../demo_data/GRN_inference/input/500_STRING_hESC/data.csv --net_file ../demo_data/GRN_inference/input/500_STRING_hESC/label.csv --setting new --alpha 100 --beta 1 --n_epoch 90 --save_name out\n",
    "!python ../main.py --task celltype_GRN --data_file ../demo_data/GRN_inference/input/500_ChIP-seq_hESC/data.csv --net_file ../demo_data/GRN_inference/input/500_ChIP-seq_hESC/label.csv --setting new --alpha 0.1 --beta 0.01 --n_epochs 150  --save_name out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate EPR values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0606707179552168"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "output = pd.read_csv('out/GRN_inference_result.tsv',sep='\\t')\n",
    "output['EdgeWeight'] = abs(output['EdgeWeight'])\n",
    "output = output.sort_values('EdgeWeight',ascending=False)\n",
    "#label = pd.read_csv('../demo_data/GRN_inference/input/500_STRING_hESC/label.csv')\n",
    "label = pd.read_csv(\"../demo_data/GRN_inference/input/500_ChIP-seq_hESC/label.csv\")\n",
    "TFs = set(label['Gene1'])\n",
    "Genes = set(label['Gene1'])| set(label['Gene2'])\n",
    "output = output[output['TF'].apply(lambda x: x in TFs)]\n",
    "output = output[output['Target'].apply(lambda x: x in Genes)]\n",
    "label_set = set(label['Gene1']+'|'+label['Gene2'])\n",
    "output = output.iloc[:len(label_set)]\n",
    "len(set(output['TF']+'|'+output['Target']) & label_set) / (len(label_set)**2/(len(TFs)*len(Genes)-len(TFs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate AUPR ratio values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC =  0.0327282671986467\n",
      "1.3633395232800607\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "output = pd.read_csv('out/GRN_inference_result.tsv',sep='\\t')\n",
    "output['EdgeWeight'] = abs(output['EdgeWeight'])\n",
    "output = output.sort_values('EdgeWeight',ascending=False)\n",
    "#label = pd.read_csv('../demo_data/GRN_inference/input/500_STRING_hESC/label.csv')\n",
    "label = pd.read_csv(\"../demo_data/GRN_inference/input/500_ChIP-seq_hESC/label.csv\")\n",
    "TFs = set(label['Gene1'])\n",
    "Genes = set(label['Gene1'])| set(label['Gene2'])\n",
    "output = output[output['TF'].apply(lambda x: x in TFs)]\n",
    "output = output[output['Target'].apply(lambda x: x in Genes)]\n",
    "label_set = set(label['Gene1']+'|'+label['Gene2'])\n",
    "preds,labels,randoms = [] ,[],[]\n",
    "res_d = {}\n",
    "l = []\n",
    "p= []\n",
    "for item in (output.to_dict('records')):\n",
    "        res_d[item['TF'] + '|' + item['Target']] = item['EdgeWeight']\n",
    "for item in (set(label['Gene1'])):\n",
    "        for item2 in  set(label['Gene1'])| set(label['Gene2']):\n",
    "            if item+ '|' + item2 in label_set:\n",
    "                l.append(1)\n",
    "            else:\n",
    "                l.append(0)\n",
    "            if item + '|' + item2 in res_d:\n",
    "                p.append(res_d[item + '|' + item2])\n",
    "            else:\n",
    "                p.append(-1)\n",
    "                \n",
    "print(\"AUPRC = \", average_precision_score(l,p))\n",
    "print(average_precision_score(l,p)/np.mean(l))\n",
    "precision, recall, thresholds = precision_recall_curve(l, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'precision')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble DeepSEM result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv does not exist: '../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17913/2596218852.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EdgeWeight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EdgeWeight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepsem/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepsem/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepsem/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepsem/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepsem/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv does not exist: '../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv'"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in range(10):\n",
    "    res.append(pd.read_csv('../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv',sep='\\t'))\n",
    "res = pd.concat(res)\n",
    "res['EdgeWeight'] = abs(res['EdgeWeight'])\n",
    "res.groupby(['Gene1','Gene2']).mean()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2738dfb9bd63bdcf641cb5b69246b4d1b6f8afb0544341910e01f4e96fcddd2e"
  },
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
