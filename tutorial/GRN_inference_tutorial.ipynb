{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Beeline benchmark to benchmark the performance of DeepSEM.\n",
    "The data preparation process are shown in below.\n",
    "1. Download raw data from https://doi.org/10.5281/zenodo.3378975, which is provided by BEELINE benchmark\n",
    "2. Use the preoprocess code in https://github.com/Murali-group/Beeline/blob/master/generateExpInputs.py to generate dataset.\n",
    "\n",
    "We also provide demo data as shown in ../demo_data/GRN_inference/input "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run DeepSEM by using following command:\n",
    "for cell type specific GRN inference task: python main.py --task non_celltype_GRN --data_file demo_data/GRN_inference/input/500_STRING_hESC/data.csv --net_file demo_data/GRN_inference/input/500_STRING_hESC/label.csv --setting new --alpha 100 --beta 1 --n_epoch 90 --save_name out\n",
    "\n",
    "\n",
    "for cell type non-specific GRN inference task: python main.py --task celltype_GRN --data_file demo_data/GRN_inference/input/500_ChIP-seq_hESC/data.csv --net_file demo_data/GRN_inference/input/500_ChIP-seq_hESC/label.csv --setting new --alpha 0.1 --beta 0.01 --n_epochs 150  --save_name out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using inverse constraint\n",
      "dir exist\n",
      "epoch: 1 Ep: 222 Epr: 2.168150853140282 loss: 1.02271302541097 mse_loss: 0.7530966401100159 kl_loss: 0.13703571011622748 sparse_loss: 0.1325806894650062\n",
      "epoch: 2 Ep: 267 Epr: 2.6076408909389883 loss: 1.0138637920220692 mse_loss: 0.7537549237410227 kl_loss: 0.12509717171390852 sparse_loss: 0.13501170774300894\n",
      "epoch: 4 Ep: 293 Epr: 2.861568468333796 loss: 0.9634573459625244 mse_loss: 0.6226864606142044 kl_loss: 0.1974144292374452 sparse_loss: 0.1433564672867457\n",
      "epoch: 5 Ep: 304 Epr: 2.9689993664623686 loss: 0.9532651752233505 mse_loss: 0.6173700739940008 kl_loss: 0.1829339601099491 sparse_loss: 0.15296114111940065\n",
      "epoch: 7 Ep: 323 Epr: 3.1545618268662667 loss: 0.9223050077756246 mse_loss: 0.5767848988374075 kl_loss: 0.18400715167323747 sparse_loss: 0.1615129572649797\n",
      "epoch: 8 Ep: 352 Epr: 3.4377887401143217 loss: 0.9148564438025156 mse_loss: 0.5697054167588552 kl_loss: 0.17542136708895364 sparse_loss: 0.16972966367999712\n",
      "epoch: 10 Ep: 349 Epr: 3.4084894042610743 loss: 0.8928407281637192 mse_loss: 0.5405952483415604 kl_loss: 0.17690855264663696 sparse_loss: 0.1753369284172853\n",
      "epoch: 11 Ep: 366 Epr: 3.574518974096141 loss: 0.8891303986310959 mse_loss: 0.5367340793212255 kl_loss: 0.1728829133013884 sparse_loss: 0.17951340228319168\n",
      "epoch: 13 Ep: 374 Epr: 3.6526505363714667 loss: 0.8774060954650243 mse_loss: 0.5203010340531667 kl_loss: 0.17530074591437975 sparse_loss: 0.18180432294805846\n",
      "epoch: 14 Ep: 359 Epr: 3.506153857105231 loss: 0.8742009401321411 mse_loss: 0.51802226404349 kl_loss: 0.17316080008943877 sparse_loss: 0.18301786482334137\n",
      "epoch: 16 Ep: 365 Epr: 3.5647525288117254 loss: 0.86383023361365 mse_loss: 0.5089629888534546 kl_loss: 0.17124790946642557 sparse_loss: 0.1836193266014258\n",
      "epoch: 17 Ep: 371 Epr: 3.6233512005182194 loss: 0.86488509674867 mse_loss: 0.5114645188053449 kl_loss: 0.16975564261277518 sparse_loss: 0.18366494526465735\n",
      "epoch: 19 Ep: 370 Epr: 3.613584755233804 loss: 0.8563922047615051 mse_loss: 0.49701033780972165 kl_loss: 0.17538370688756308 sparse_loss: 0.18399816254774728\n",
      "epoch: 20 Ep: 372 Epr: 3.6331176458026353 loss: 0.8559152881304423 mse_loss: 0.49752431859572727 kl_loss: 0.17412776748339334 sparse_loss: 0.18426320080955824\n",
      "epoch: 22 Ep: 367 Epr: 3.584285419380557 loss: 0.8499229600032171 mse_loss: 0.4918345386783282 kl_loss: 0.1741244668761889 sparse_loss: 0.18396396189928055\n",
      "epoch: 23 Ep: 373 Epr: 3.642884091087051 loss: 0.8478853702545166 mse_loss: 0.4914197673400243 kl_loss: 0.1728778046866258 sparse_loss: 0.1835878019531568\n",
      "epoch: 25 Ep: 386 Epr: 3.769847879784455 loss: 0.8448104659716288 mse_loss: 0.4881361772616704 kl_loss: 0.17336967463294664 sparse_loss: 0.18330460662643114\n",
      "epoch: 26 Ep: 388 Epr: 3.789380770353286 loss: 0.8449686070283254 mse_loss: 0.4893537685275078 kl_loss: 0.1726756493250529 sparse_loss: 0.1829391879340013\n",
      "epoch: 28 Ep: 385 Epr: 3.760081434500039 loss: 0.8413474063078562 mse_loss: 0.48465897887945175 kl_loss: 0.1741622326274713 sparse_loss: 0.18252620473504066\n",
      "epoch: 29 Ep: 386 Epr: 3.769847879784455 loss: 0.8415094216664633 mse_loss: 0.48589038600524265 kl_loss: 0.17332213992873827 sparse_loss: 0.182296900699536\n",
      "epoch: 31 Ep: 379 Epr: 3.701482762793545 loss: 0.8387279510498047 mse_loss: 0.48240966349840164 kl_loss: 0.17436878507335982 sparse_loss: 0.18194951489567757\n",
      "epoch: 32 Ep: 380 Epr: 3.7112492080779607 loss: 0.83731809258461 mse_loss: 0.4822615360220273 kl_loss: 0.17347314208745956 sparse_loss: 0.18158341695864996\n",
      "epoch: 34 Ep: 376 Epr: 3.6721834269402978 loss: 0.834411104520162 mse_loss: 0.4774370441834132 kl_loss: 0.17572971557577452 sparse_loss: 0.18124433731039366\n",
      "epoch: 35 Ep: 373 Epr: 3.642884091087051 loss: 0.833614374200503 mse_loss: 0.4779493411382039 kl_loss: 0.1747287412484487 sparse_loss: 0.18093629429737726\n",
      "epoch: 37 Ep: 380 Epr: 3.7112492080779607 loss: 0.8331021815538406 mse_loss: 0.47657573968172073 kl_loss: 0.1757320687174797 sparse_loss: 0.1807943806052208\n",
      "epoch: 38 Ep: 378 Epr: 3.691716317509129 loss: 0.8302116493384043 mse_loss: 0.47454828520615894 kl_loss: 0.17507708817720413 sparse_loss: 0.18058627843856812\n",
      "epoch: 40 Ep: 374 Epr: 3.6526505363714667 loss: 0.8291561802228292 mse_loss: 0.4736706241965294 kl_loss: 0.1751354249815146 sparse_loss: 0.18035012980302176\n",
      "epoch: 41 Ep: 377 Epr: 3.6819498722247137 loss: 0.8274573882420858 mse_loss: 0.47300191471974057 kl_loss: 0.17433521648248038 sparse_loss: 0.18012025083104768\n",
      "epoch: 43 Ep: 375 Epr: 3.6624169816558823 loss: 0.829564611117045 mse_loss: 0.47435233493645984 kl_loss: 0.1752722735206286 sparse_loss: 0.1799400088687738\n",
      "epoch: 44 Ep: 378 Epr: 3.691716317509129 loss: 0.8269262959559759 mse_loss: 0.4722682386636734 kl_loss: 0.17487788572907448 sparse_loss: 0.17978016659617424\n",
      "epoch: 46 Ep: 379 Epr: 3.701482762793545 loss: 0.8271809717019399 mse_loss: 0.4714691986640294 kl_loss: 0.1761295311152935 sparse_loss: 0.17958223323027292\n",
      "epoch: 47 Ep: 379 Epr: 3.701482762793545 loss: 0.8268081694841385 mse_loss: 0.4719715192914009 kl_loss: 0.17546230306228003 sparse_loss: 0.1793743371963501\n",
      "epoch: 49 Ep: 383 Epr: 3.7405485439312076 loss: 0.8268401622772217 mse_loss: 0.47125595311323804 kl_loss: 0.17630818858742714 sparse_loss: 0.17927602057655653\n",
      "epoch: 50 Ep: 383 Epr: 3.7405485439312076 loss: 0.8259805142879486 mse_loss: 0.47114203373591107 kl_loss: 0.17575296635429064 sparse_loss: 0.1790855179230372\n",
      "epoch: 52 Ep: 384 Epr: 3.7503149892156236 loss: 0.8228529691696167 mse_loss: 0.4680263201395671 kl_loss: 0.17595627531409264 sparse_loss: 0.17887038240830103\n",
      "epoch: 53 Ep: 386 Epr: 3.769847879784455 loss: 0.823633223772049 mse_loss: 0.469507855673631 kl_loss: 0.17540591210126877 sparse_loss: 0.1787194460630417\n",
      "epoch: 55 Ep: 390 Epr: 3.8089136609221175 loss: 0.8218846668799719 mse_loss: 0.46714744716882706 kl_loss: 0.1761487474044164 sparse_loss: 0.17858846113085747\n",
      "epoch: 56 Ep: 392 Epr: 3.828446551490949 loss: 0.8217032651106516 mse_loss: 0.46781618644793826 kl_loss: 0.17539557814598083 sparse_loss: 0.17849149803320566\n",
      "epoch: 58 Ep: 387 Epr: 3.7796143250688705 loss: 0.8215944617986679 mse_loss: 0.46757860233386356 kl_loss: 0.1756030172109604 sparse_loss: 0.17841284101208052\n",
      "epoch: 59 Ep: 386 Epr: 3.769847879784455 loss: 0.8207236776749293 mse_loss: 0.4672895024220149 kl_loss: 0.17507791394988695 sparse_loss: 0.17835625385244688\n",
      "epoch: 61 Ep: 390 Epr: 3.8089136609221175 loss: 0.8192257086435953 mse_loss: 0.4655253017942111 kl_loss: 0.17545361071825027 sparse_loss: 0.1782467948893706\n",
      "epoch: 62 Ep: 391 Epr: 3.8186801062065334 loss: 0.819795161485672 mse_loss: 0.4663177927335103 kl_loss: 0.175247756143411 sparse_loss: 0.17822961633404097\n",
      "epoch: 64 Ep: 390 Epr: 3.8089136609221175 loss: 0.8178607324759165 mse_loss: 0.4638974244395892 kl_loss: 0.17580813790361086 sparse_loss: 0.17815516144037247\n",
      "epoch: 65 Ep: 392 Epr: 3.828446551490949 loss: 0.820079912741979 mse_loss: 0.4666416198015213 kl_loss: 0.17529086271921793 sparse_loss: 0.17814744263887405\n",
      "epoch: 67 Ep: 395 Epr: 3.857745887344196 loss: 0.8178698023160299 mse_loss: 0.4637373760342598 kl_loss: 0.1760858123501142 sparse_loss: 0.17804661889870962\n",
      "epoch: 68 Ep: 398 Epr: 3.8870452231974433 loss: 0.8200528174638748 mse_loss: 0.46631041417519253 kl_loss: 0.17580763871471086 sparse_loss: 0.177934763332208\n",
      "epoch: 70 Ep: 396 Epr: 3.867512332628612 loss: 0.8190968334674835 mse_loss: 0.4651441847284635 kl_loss: 0.17606215924024582 sparse_loss: 0.17789049074053764\n",
      "epoch: 71 Ep: 392 Epr: 3.828446551490949 loss: 0.8161648710568746 mse_loss: 0.46312480171521503 kl_loss: 0.17523792261878648 sparse_loss: 0.17780215044816336\n",
      "epoch: 73 Ep: 393 Epr: 3.8382129967753644 loss: 0.8155167798201243 mse_loss: 0.46222994724909466 kl_loss: 0.17546826104323068 sparse_loss: 0.17781856283545494\n",
      "epoch: 74 Ep: 392 Epr: 3.828446551490949 loss: 0.8158389876286188 mse_loss: 0.4630143493413925 kl_loss: 0.1750704695781072 sparse_loss: 0.17775417491793633\n",
      "epoch: 76 Ep: 396 Epr: 3.867512332628612 loss: 0.8167201727628708 mse_loss: 0.4632551024357478 kl_loss: 0.1756691907842954 sparse_loss: 0.1777958981692791\n",
      "epoch: 77 Ep: 393 Epr: 3.8382129967753644 loss: 0.8170665800571442 mse_loss: 0.4639151046673457 kl_loss: 0.1753376697500547 sparse_loss: 0.17781380439798036\n",
      "epoch: 79 Ep: 395 Epr: 3.857745887344196 loss: 0.8163819760084152 mse_loss: 0.4626426299413045 kl_loss: 0.17586508269111314 sparse_loss: 0.17787425592541695\n",
      "epoch: 80 Ep: 392 Epr: 3.828446551490949 loss: 0.8143956412871679 mse_loss: 0.4611582060654958 kl_loss: 0.17547224710385004 sparse_loss: 0.17776518811782202\n",
      "epoch: 82 Ep: 393 Epr: 3.8382129967753644 loss: 0.8151271641254425 mse_loss: 0.46190578242142993 kl_loss: 0.17544448872407278 sparse_loss: 0.1777768904964129\n",
      "epoch: 83 Ep: 399 Epr: 3.896811668481859 loss: 0.8152563273906708 mse_loss: 0.4622573082645734 kl_loss: 0.17520743732651076 sparse_loss: 0.17779158179958662\n",
      "epoch: 85 Ep: 399 Epr: 3.896811668481859 loss: 0.8160101274649302 mse_loss: 0.4625418062011401 kl_loss: 0.17566844572623572 sparse_loss: 0.17779986808697382\n",
      "epoch: 86 Ep: 399 Epr: 3.896811668481859 loss: 0.8129114409287771 mse_loss: 0.45996037125587463 kl_loss: 0.17520401875178018 sparse_loss: 0.1777470534046491\n",
      "epoch: 88 Ep: 400 Epr: 3.9065781137662743 loss: 0.8153532445430756 mse_loss: 0.46218758324782055 kl_loss: 0.17539468283454576 sparse_loss: 0.17777097846070924\n",
      "epoch: 89 Ep: 396 Epr: 3.867512332628612 loss: 0.8142229318618774 mse_loss: 0.4614272067944209 kl_loss: 0.1750603032608827 sparse_loss: 0.17773542429010072\n"
     ]
    }
   ],
   "source": [
    "!python ../main.py --task non_celltype_GRN --data_file ../demo_data/GRN_inference/input/500_STRING_hESC/data.csv --net_file ../demo_data/GRN_inference/input/500_STRING_hESC/label.csv --setting new --alpha 100 --beta 1 --n_epoch 90 --save_name out\n",
    "#!python ../main.py --task celltype_GRN --data_file ../demo_data/GRN_inference/input/500_ChIP-seq_hESC/data.csv --net_file ../demo_data/GRN_inference/input/500_ChIP-seq_hESC/label.csv --setting new --alpha 0.1 --beta 0.01 --n_epochs 150  --save_name out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate EPR values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.867512332628612"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#col1 = \"Gene1\"\n",
    "#col2 = \"Gene2\"\n",
    "col1 = \"TF\"\n",
    "col2 = \"Target\"\n",
    "output = pd.read_csv(\"out/GRN_inference_result.tsv\",sep='\\t')\n",
    "output['EdgeWeight'] = abs(output['EdgeWeight'])\n",
    "output = output.sort_values('EdgeWeight',ascending=False)\n",
    "label = pd.read_csv('../demo_data/GRN_inference/input/500_STRING_hESC/label.csv')\n",
    "#label = pd.read_csv(\"../demo_data/GRN_inference/input/500_ChIP-seq_hESC/label.csv\")\n",
    "TFs = set(label['Gene1'])\n",
    "Genes = set(label['Gene1'])| set(label['Gene2'])\n",
    "output = output[output[col1].apply(lambda x: x in TFs)]\n",
    "output = output[output[col2].apply(lambda x: x in Genes)]\n",
    "label_set = set(label['Gene1']+'|'+label['Gene2'])\n",
    "output = output.iloc[:len(label_set)]\n",
    "len(set(output[col1]+'|'+output[col2]) & label_set) / (len(label_set)**2/(len(TFs)*len(Genes)-len(TFs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate AUPR ratio values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC =  0.0469393325430154\n",
      "1.9553203615657655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "output = pd.read_csv(\"out/GRN_inference_result.tsv\",sep='\\t')\n",
    "output['EdgeWeight'] = abs(output['EdgeWeight'])\n",
    "output = output.sort_values('EdgeWeight',ascending=False)\n",
    "label = pd.read_csv('../demo_data/GRN_inference/input/500_STRING_hESC/label.csv')\n",
    "#label = pd.read_csv(\"../demo_data/GRN_inference/input/500_ChIP-seq_hESC/label.csv\")\n",
    "TFs = set(label['Gene1'])\n",
    "Genes = set(label['Gene1'])| set(label['Gene2'])\n",
    "output = output[output[col1].apply(lambda x: x in TFs)]\n",
    "output = output[output[col2].apply(lambda x: x in Genes)]\n",
    "label_set = set(label['Gene1']+'|'+label['Gene2'])\n",
    "preds,labels,randoms = [] ,[],[]\n",
    "res_d = {}\n",
    "l = []\n",
    "p= []\n",
    "for item in (output.to_dict('records')):\n",
    "        res_d[item[col1] + '|' + item[col2]] = item['EdgeWeight']\n",
    "for item in (set(label['Gene1'])):\n",
    "        for item2 in  set(label['Gene1'])| set(label['Gene2']):\n",
    "            if item+ '|' + item2 in label_set:\n",
    "                l.append(1)\n",
    "            else:\n",
    "                l.append(0)\n",
    "            if item + '|' + item2 in res_d:\n",
    "                p.append(res_d[item + '|' + item2])\n",
    "            else:\n",
    "                p.append(-1)\n",
    "                \n",
    "print(\"AUPRC = \", average_precision_score(l,p))\n",
    "print(average_precision_score(l,p)/np.mean(l))\n",
    "precision, recall, thresholds = precision_recall_curve(l, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'precision')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble DeepSEM result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv does not exist: '../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17913/2596218852.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EdgeWeight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EdgeWeight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepsem/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepsem/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepsem/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepsem/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deepsem/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv does not exist: '../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv'"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in range(10):\n",
    "    res.append(pd.read_csv('../../scGRN/Upload/GRN_inference_benchmark/cross_validation/500_STRING_hESC/rep_i.csv',sep='\\t'))\n",
    "res = pd.concat(res)\n",
    "res['EdgeWeight'] = abs(res['EdgeWeight'])\n",
    "res.groupby(['Gene1','Gene2']).mean()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2738dfb9bd63bdcf641cb5b69246b4d1b6f8afb0544341910e01f4e96fcddd2e"
  },
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
